{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import dbfread\n",
    "from dbfread import DBF\n",
    "import dbf\n",
    "from glob import glob \n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc, font_manager\n",
    "import plotly as py\n",
    "from plotly import graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "# font_list = fm.findSystemFonts(fontpaths=None, fontext = 'ttf')\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "# font_path = \"C:/Windows/Fonts/NGULIM.TTF\"\n",
    "# font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "# rc('font', family=font)\n",
    "rc('font', family='AppleGothic')\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jangy\\miniconda3\\envs\\model\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras import layers, optimizers, models\n",
    "from tensorflow.keras.layers import BatchNormalization, Bidirectional, Activation \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('../dataset')\n",
    "dir_data = os.getcwd() #현재 작업 디렉토리를 가져와 변수에 저장\n",
    "filename = 'lab_DATASET_v16.pickle' \n",
    "#audio_filename = 'lab_DATASET_audio_new_v1.pickle'\n",
    "\n",
    "with open(os.path.join(dir_data, filename), 'rb') as f:\n",
    "  DATASET = pickle.load(f)\n",
    "# with open(os.path.join(dir_data, audio_filename), 'rb') as f:\n",
    "#   audio_DATASET = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pnum = [1,2,3,4,8,10,12,13,14,16,18,19,20,21,22,23,25,26,27]\n",
    "# for p in pnum:\n",
    "#     audio_DATASET[str(p)]['data']['audio_worker'] = audio_DATASET[str(p)]['data']['audio_worker'].drop(['mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13'], axis=1)\n",
    "#     audio_DATASET[str(p)]['data']['audio_customer'] = audio_DATASET[str(p)]['data']['audio_customer'].drop(['mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# pnum = [1,2,3,4,8,9,10,12,13,14,15,16,18,19,20,21,22,23,25,26,27] # 5: 임산부 / 6: voice없음 / 7: 라벨없음 / 11,17: E4이상 / 24: 임산부\n",
    "# pnum = [1,2,3,4,8,10,12,13,14,15,16,18,19,20,21,22,23,25,26,27] # 5: 임산부 / 6: voice없음 / 7: 라벨없음 / 9: 웃기다고함 / 11,17: E4이상 / 24: 임산부\n",
    "#pnum = [1,2,3,4,8,10,12,13,14,16,18,19,20,21,22,23,25,26,27] # 5: 임산부 / 6: voice없음 / 7: 라벨없음 / 9: 웃기다고함 / 11,17: E4이상 / 24: 임산부 / 15: 높은 PSS 점수\n",
    "pnum = [1]\n",
    "print(len(pnum))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1671068339984   1671069492344\n",
      "pnum:  1\n",
      "EDA length:  1143\n",
      "EEG length:  1143\n",
      "TEMP length:  1143\n",
      "ACC length:  1148\n",
      "ECG HRV length:  1142\n",
      "ECG HR length:  1141\n",
      "LABEL length:  1148\n",
      "1141\n",
      "1141\n",
      "1141\n",
      "1141\n",
      "1141\n",
      "1141\n",
      "1141\n",
      "1141\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from model_utils import eda_mean, eda_count_peaks, eeg_mean_bandpower, temp_mean, signal_interp, label_bin, acc_mag_mean, ecg_hrv, ecg_hr, max_audio, min_audio, std_audio, mean_audio\n",
    "# import model_utils\n",
    "\n",
    "# EEG 샘플링 레이트와 레이블 이름 지\n",
    "eeg_sampling_rate = 256\n",
    "label_name = 'suppress'\n",
    "\n",
    "# 다양한 윈도우 및 슬라이딩 값들\n",
    "# window = 10 \n",
    "physi_window = 10\n",
    "audio_window = 5\n",
    "acc_window = 5\n",
    "label_window = 5\n",
    "slide = 1\n",
    "\n",
    "# # window = 60\n",
    "# physi_window = 60\n",
    "# audio_window = 5\n",
    "# acc_window = 5\n",
    "# label_window = 5\n",
    "# slide = 1\n",
    "\n",
    "call_label = False\n",
    "call_three_label = False\n",
    "\n",
    "# 데이터를 저장할 데이터프레임들을 초기화합니다.\n",
    "EDA_MEAN = pd.DataFrame()\n",
    "EDA_PEAK = pd.DataFrame()\n",
    "EEG_MEAN_BANDPOWER = pd.DataFrame()\n",
    "TEMP_MEAN = pd.DataFrame()\n",
    "ACC_MEAN = pd.DataFrame()\n",
    "ECG_HRV = pd.DataFrame()\n",
    "ECG_HR = pd.DataFrame()\n",
    "AUDIO_CUSTOMER = pd.DataFrame()\n",
    "AUDIO_WORKER = pd.DataFrame()\n",
    "LABEL = pd.DataFrame()\n",
    "\n",
    "PNUM = pd.DataFrame()\n",
    "\n",
    "for i in pnum:\n",
    "    eda_data = DATASET[str(i)]['data']['e4_eda']\n",
    "    eeg_data = DATASET[str(i)]['data']['muse']\n",
    "    temp_data = DATASET[str(i)]['data']['e4_temp']\n",
    "    acc_data = DATASET[str(i)]['data']['e4_acc']\n",
    "    ecg_rr_data = DATASET[str(i)]['data']['polar_rr']\n",
    "    ecg_hr_data = DATASET[str(i)]['data']['polar_hr']\n",
    "    #audio_customer_data = audio_DATASET[str(i)]['data']['audio_customer']\n",
    "    #audio_customer_data['voiced_flag'] = audio_customer_data['voiced_flag'].astype(int)\n",
    "    #audio_worker_data = audio_DATASET[str(i)]['data']['audio_worker']\n",
    "    #audio_worker_data['voiced_flag'] = audio_worker_data['voiced_flag'].astype(int)\n",
    "\n",
    "    label_data = DATASET[str(i)]['labels'][label_name]\n",
    "    \n",
    "\n",
    "    # interpolation\n",
    "    eeg_data = signal_interp(eeg_data, 256)\n",
    "\n",
    "    # Data crop\n",
    "    t_eda = eda_data['Timestamp'].tolist()\n",
    "    t_eeg = eeg_data['Timestamp'].tolist()\n",
    "    t_temp = temp_data['Timestamp'].tolist()\n",
    "    t_acc = acc_data['Timestamp'].tolist()\n",
    "    t_ecg_rr = ecg_rr_data['Timestamp'].tolist()\n",
    "    t_ecg_hr = ecg_hr_data['Timestamp'].tolist()\n",
    "    #t_audio_customer = audio_customer_data['time'].tolist()\n",
    "    #t_audio_worker = audio_worker_data['time'].tolist()\n",
    "    t_label = label_data['Timestamp'].tolist()\n",
    "\n",
    "    max_start = max(t_eda[0], t_eeg[0], t_temp[0], t_acc[0], t_ecg_rr[0], t_ecg_hr[0], \n",
    "                    #t_audio_customer[0], t_audio_worker[0], \n",
    "                    t_label[0])\n",
    "    min_end = min(t_eda[-1], t_eeg[-1], t_temp[-1], t_acc[-1], t_ecg_rr[-1], t_ecg_hr[-1], \n",
    "                  #t_audio_customer[-1], t_audio_worker[-1], \n",
    "                  t_label[-1])\n",
    "\n",
    "    \n",
    "    print(max_start, ' ' ,min_end)\n",
    "\n",
    "    eda_data = eda_data.loc[(eda_data['Timestamp']>=max_start) & (eda_data['Timestamp']<=min_end)]\n",
    "    eeg_data = eeg_data.loc[(eeg_data['Timestamp']>=max_start) & (eeg_data['Timestamp']<=min_end)] \n",
    "    temp_data = temp_data.loc[(temp_data['Timestamp']>=max_start) & (temp_data['Timestamp']<=min_end)]\n",
    "    acc_data = acc_data.loc[(acc_data['Timestamp']>=max_start) & (acc_data['Timestamp']<=min_end)]\n",
    "    ecg_rr_data = ecg_rr_data.loc[(ecg_rr_data['Timestamp']>=max_start) & (ecg_rr_data['Timestamp']<=min_end)]\n",
    "    ecg_hr_data = ecg_hr_data.loc[(ecg_hr_data['Timestamp']>=max_start) & (ecg_hr_data['Timestamp']<=min_end)]\n",
    "    #audio_customer_data = audio_customer_data.loc[(audio_customer_data['time']>=max_start) & (audio_customer_data['time']<=min_end)]\n",
    "    #audio_worker_data = audio_worker_data.loc[(audio_worker_data['time']>=max_start) & (audio_worker_data['time']<=min_end)]\n",
    "    label_data = label_data.loc[(label_data['Timestamp']>=max_start) & (label_data['Timestamp']<=min_end)]        \n",
    "\n",
    "    # eda_mean\n",
    "    out_eda_mean = eda_mean(eda_data, physi_window, slide)\n",
    "\n",
    "    # eda_count_peaks\n",
    "    out_eda_peak = eda_count_peaks(eda_data, physi_window, slide)\n",
    "\n",
    "    # eeg_mean_bandpower\n",
    "    out_eeg_meanbp = eeg_mean_bandpower(eeg_data, sampling_rate=256, window=physi_window, slide=slide, show=False)\n",
    "\n",
    "    # temp_mean\n",
    "    out_temp_mean = temp_mean(temp_data, physi_window, slide)\n",
    "    \n",
    "    # acc_mean\n",
    "    out_acc_mag_mean = acc_mag_mean(acc_data, acc_window, slide)\n",
    "\n",
    "    # ecg_hrv\n",
    "    out_ecg_hrv = ecg_hrv(ecg_rr_data, physi_window, slide)\n",
    "\n",
    "    # ecg_hr\n",
    "    out_ecg_hr = ecg_hr(ecg_hr_data, physi_window, slide)\n",
    "\n",
    "    # audio_customer\n",
    "    #out_audio_customer_mean, out_audio_customer_min, out_audio_customer_max, out_audio_customer_std = mean_audio(audio_customer_data, audio_window, slide), min_audio(audio_customer_data, audio_window, slide), max_audio(audio_customer_data, audio_window, slide), std_audio(audio_customer_data, audio_window, slide)\n",
    "\n",
    "    # audio_worker\n",
    "    #out_audio_worker_mean, out_audio_worker_min, out_audio_worker_max, out_audio_worker_std = mean_audio(audio_worker_data, audio_window, slide), min_audio(audio_worker_data, audio_window, slide), max_audio(audio_worker_data, audio_window, slide), std_audio(audio_worker_data, audio_window, slide)\n",
    "\n",
    "    # label binning\n",
    "    label = label_bin(label_data, label_name, label_window, slide)\n",
    "    label['pnum'] = i\n",
    "\n",
    "    print('pnum: ', i)\n",
    "    print('EDA length: ', len(out_eda_mean))\n",
    "    print('EEG length: ', len(out_eeg_meanbp))\n",
    "    print('TEMP length: ', len(out_temp_mean))\n",
    "    print('ACC length: ', len(out_acc_mag_mean))\n",
    "    print('ECG HRV length: ', len(out_ecg_hrv))\n",
    "    print('ECG HR length: ', len(out_ecg_hr))\n",
    "    #print('AUDIO customer length: ', len(out_audio_customer_mean))\n",
    "    #print('AUDIO worker length: ', len(out_audio_worker_mean))\n",
    "    print('LABEL length: ', len(label))\n",
    "\n",
    "\n",
    "    min_len = min(len(out_eda_mean), len(out_eeg_meanbp), len(out_temp_mean), len(out_acc_mag_mean), len(out_ecg_hrv), len(out_ecg_hr),\n",
    "                  #len(out_audio_customer_mean), len(out_audio_customer_min), len(out_audio_customer_max), len(out_audio_customer_std),\n",
    "                  #len(out_audio_worker_mean), len(out_audio_worker_min), len(out_audio_worker_max), len(out_audio_worker_std), \n",
    "                  len(label))\n",
    "\n",
    "    EDA_MEAN = pd.concat([EDA_MEAN, out_eda_mean.iloc[0:min_len]])\n",
    "    EDA_PEAK = pd.concat([EDA_PEAK, out_eda_peak.iloc[0:min_len]])\n",
    "    EEG_MEAN_BANDPOWER = pd.concat([EEG_MEAN_BANDPOWER, out_eeg_meanbp.iloc[0:min_len]])\n",
    "    TEMP_MEAN = pd.concat([TEMP_MEAN, out_temp_mean.iloc[0:min_len]])\n",
    "    ACC_MEAN = pd.concat([ACC_MEAN, out_acc_mag_mean.iloc[0:min_len]])\n",
    "    ECG_HRV = pd.concat([ECG_HRV, out_ecg_hrv.iloc[0:min_len]])\n",
    "    ECG_HR = pd.concat([ECG_HR, out_ecg_hr.iloc[0:min_len]])\n",
    "    # AUDIO_CUSTOMER_add = pd.concat([out_audio_customer_max.iloc[0:min_len], out_audio_customer_min.iloc[0:min_len], out_audio_customer_mean.iloc[0:min_len], out_audio_customer_std.iloc[0:min_len]], axis=1)\n",
    "    # AUDIO_CUSTOMER = pd.concat([AUDIO_CUSTOMER, AUDIO_CUSTOMER_add])\n",
    "    # AUDIO_WORKER_add = pd.concat([out_audio_worker_mean.iloc[0:min_len], out_audio_worker_min.iloc[0:min_len], out_audio_worker_max.iloc[0:min_len], out_audio_worker_std.iloc[0:min_len]], axis=1)\n",
    "    # AUDIO_WORKER = pd.concat([AUDIO_WORKER, AUDIO_WORKER_add])\n",
    "    LABEL = pd.concat([LABEL, label.iloc[0:min_len]])\n",
    "\n",
    "    \n",
    "\n",
    "#AUDIO_CUSTOMER = AUDIO_CUSTOMER.add_prefix('customer_')\n",
    "#AUDIO_WORKER = AUDIO_WORKER.add_prefix('worker_')\n",
    "\n",
    "print(len(EDA_MEAN))\n",
    "print(len(EDA_PEAK))\n",
    "print(len(EEG_MEAN_BANDPOWER))\n",
    "print(len(TEMP_MEAN))\n",
    "print(len(ACC_MEAN))\n",
    "print(len(ECG_HRV))\n",
    "print(len(ECG_HR))\n",
    "#print(len(AUDIO_CUSTOMER))\n",
    "#print(len(AUDIO_WORKER))\n",
    "print(len(LABEL))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call label (\bthree-label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_three_label = True\n",
    "\n",
    "\n",
    "if call_three_label: \n",
    "    call_three_label = []\n",
    "\n",
    "    for p in pnum: \n",
    "        marker = DATASET[str(p)]['data']['marker']\n",
    "        label_p = LABEL.loc[LABEL['pnum']==p]\n",
    "\n",
    "        label_p['call_three_label'] = np.nan\n",
    "\n",
    "        c1_s = marker['Timestamp'][marker['session']=='c1_start']\n",
    "        c1_e = marker['Timestamp'][marker['session']=='c1_end']\n",
    "        c2_s = marker['Timestamp'][marker['session']=='c2_start']\n",
    "        c2_e = marker['Timestamp'][marker['session']=='c2_end']\n",
    "        c3_s = marker['Timestamp'][marker['session']=='c3_start']\n",
    "        c3_e = marker['Timestamp'][marker['session']=='c3_end']\n",
    "\n",
    "        if p%2 == 1:\n",
    "            label_p.loc[(label_p['Timestamp'] >= c1_s.values[0]) & (label_p['Timestamp'] <= c1_e.values[0]), 'call_three_label'] = 0\n",
    "            label_p.loc[(label_p['Timestamp'] >= c2_s.values[0]) & (label_p['Timestamp'] <= c2_e.values[0]), 'call_three_label'] = 1\n",
    "            label_p.loc[(label_p['Timestamp'] >= c3_s.values[0]) & (label_p['Timestamp'] <= c3_e.values[0]), 'call_three_label'] = 2\n",
    "        elif p%2 == 0: \n",
    "            label_p.loc[(label_p['Timestamp'] >= c1_s.values[0]) & (label_p['Timestamp'] <= c1_e.values[0]), 'call_three_label'] = 0\n",
    "            label_p.loc[(label_p['Timestamp'] >= c2_s.values[0]) & (label_p['Timestamp'] <= c2_e.values[0]), 'call_three_label'] = 2\n",
    "            label_p.loc[(label_p['Timestamp'] >= c3_s.values[0]) & (label_p['Timestamp'] <= c3_e.values[0]), 'call_three_label'] = 1\n",
    "\n",
    "\n",
    "        call_three_label.extend(label_p['call_three_label'])\n",
    "\n",
    "    LABEL['call_three_label'] = call_three_label\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call label (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_label = True\n",
    "\n",
    "if call_label:\n",
    "    call_label = [] \n",
    "\n",
    "    for p in pnum:\n",
    "        marker = DATASET[str(p)]['data']['marker']\n",
    "        label_p = LABEL.loc[LABEL['pnum']==p]\n",
    "\n",
    "        # LABEL = LABEL.reset_index(drop=True)\n",
    "        # marker['Timestamp'] = marker['Timestamp'].reset_index(drop=True)\n",
    "\n",
    "        label_p['call_label'] = np.nan\n",
    "\n",
    "        c1_s = marker['Timestamp'][marker['session']=='c1_start']\n",
    "        c1_e = marker['Timestamp'][marker['session']=='c1_end']\n",
    "        c2_s = marker['Timestamp'][marker['session']=='c2_start']\n",
    "        c2_e = marker['Timestamp'][marker['session']=='c2_end']\n",
    "        c3_s = marker['Timestamp'][marker['session']=='c3_start']\n",
    "        c3_e = marker['Timestamp'][marker['session']=='c3_end']\n",
    "\n",
    "        label_p.loc[(label_p['Timestamp'] >= c1_s.values[0]) & (label_p['Timestamp'] <= c1_e.values[0]), 'call_label'] = 0\n",
    "        label_p.loc[(label_p['Timestamp'] >= c2_s.values[0]) & (label_p['Timestamp'] <= c2_e.values[0]), 'call_label'] = 1\n",
    "        label_p.loc[(label_p['Timestamp'] >= c3_s.values[0]) & (label_p['Timestamp'] <= c3_e.values[0]), 'call_label'] = 1\n",
    "\n",
    "        call_label.extend(label_p['call_label'])\n",
    "\n",
    "    LABEL['call_label'] = call_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Audio features normalization\n",
    "# AUDIO_CUSTOMER = pd.DataFrame(scaler.fit_transform(AUDIO_CUSTOMER), columns=AUDIO_CUSTOMER.columns)\n",
    "# AUDIO_WORKER = pd.DataFrame(scaler.fit_transform(AUDIO_WORKER), columns=AUDIO_WORKER.columns)\n",
    "\n",
    "# # E: 데이터 다시 Load 안해도 되게 원본데이터 보존하려고 temp_ 붙여서 feature combining 하는 것으로 변경\n",
    "# temp_AUDIO_CUSTOMER = AUDIO_CUSTOMER.drop(columns='customer_Timestamp').reset_index(drop=True)\n",
    "# temp_AUDIO_WORKER = AUDIO_WORKER.drop(columns='worker_Timestamp').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated features (230) ==> 228개 같아요 (Pnum, suppress, binarized 제외)\n",
    "\n",
    "#temp_AUDIO_CUSTOMER = AUDIO_CUSTOMER.drop(columns='customer_Timestamp').reset_index(drop=True)\n",
    "#temp_AUDIO_WORKER = AUDIO_WORKER.drop(columns='worker_Timestamp').reset_index(drop=True)\n",
    "\n",
    "temp_EDA_MEAN = EDA_MEAN[EDA_MEAN.columns.drop('Timestamp')].reset_index(drop=True)\n",
    "temp_EDA_PEAK = EDA_PEAK[EDA_PEAK.columns.drop('Timestamp')].reset_index(drop=True)\n",
    "temp_EEG_MEAN_BANDPOWER = EEG_MEAN_BANDPOWER[EEG_MEAN_BANDPOWER.columns.drop('Timestamp')].reset_index(drop=True)\n",
    "temp_TEMP_MEAN = TEMP_MEAN[TEMP_MEAN.columns.drop('Timestamp')].reset_index(drop=True)\n",
    "temp_ACC_MEAN = ACC_MEAN[ACC_MEAN.columns.drop('Timestamp')].reset_index(drop=True)\n",
    "temp_ECG_HRV = ECG_HRV[ECG_HRV.columns.drop(['Timestamp', 'Datetime'])].reset_index(drop=True)\n",
    "temp_ECG_HR = ECG_HR[ECG_HR.columns.drop(['Timestamp', 'Datetime'])].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# old features (210)\n",
    "# temp_EDA_MEAN = EDA_MEAN[['phasic_mean', 'tonic_mean']].reset_index(drop=True)\n",
    "# temp_EDA_PEAK = EDA_PEAK[EDA_PEAK.columns.drop('Timestamp')].reset_index(drop=True)\n",
    "# temp_EEG_MEAN_BANDPOWER = EEG_MEAN_BANDPOWER[EEG_MEAN_BANDPOWER.columns.drop('Timestamp')].reset_index(drop=True)\n",
    "# temp_TEMP_MEAN = TEMP_MEAN[['temp_mean']].reset_index(drop=True)\n",
    "# temp_ACC_MEAN = ACC_MEAN[['acc_magnitude']].reset_index(drop=True)\n",
    "# temp_ECG_HRV = ECG_HRV[ECG_HRV.columns.drop(['Timestamp', 'Datetime'])].reset_index(drop=True)\n",
    "# temp_ECG_HR = ECG_HR[ECG_HR.columns.drop(['Timestamp', 'Datetime'])].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# if call_label: \n",
    "#     temp_LABEL = LABEL[['call_label', 'pnum']].reset_index(drop=True)\n",
    "# elif call_three_label:\n",
    "#     temp_LABEL = LABEL[['call_three_label', 'pnum']].reset_index(drop=True)\n",
    "# else:\n",
    "#     temp_LABEL = LABEL[[label_name, 'pnum']].reset_index(drop=True)\n",
    "\n",
    "temp_LABEL = LABEL[['call_label', 'call_three_label', label_name, 'pnum']].reset_index(drop=True)\n",
    "\n",
    "# (1) Only situational cues\n",
    "# result = pd.concat([temp_AUDIO_CUSTOMER, temp_LABEL], axis=1)\n",
    "\n",
    "# (2) Only required emotion response \n",
    "# result = pd.concat([temp_AUDIO_WORKER, temp_LABEL], axis=1)\n",
    "\n",
    "# (3) Only Not-required emotion response\n",
    "# result = pd.concat([temp_ACC_MEAN, temp_EDA_MEAN, temp_EDA_PEAK, temp_EEG_MEAN_BANDPOWER, temp_TEMP_MEAN, temp_ECG_HRV, temp_ECG_HR, temp_LABEL], axis=1)\n",
    "\n",
    "# (4) Situational cues + Required emotion response\n",
    "# result = pd.concat([temp_AUDIO_CUSTOMER, temp_AUDIO_WORKER, temp_LABEL], axis=1)\n",
    "\n",
    "# (5) Required emotion response + not-required emotion response\n",
    "# result = pd.concat([temp_AUDIO_WORKER, temp_ACC_MEAN, temp_EDA_MEAN, temp_EDA_PEAK, temp_EEG_MEAN_BANDPOWER, temp_TEMP_MEAN, temp_ECG_HRV, temp_ECG_HR, temp_LABEL], axis=1)\n",
    "\n",
    "# (6) Situational cues + not_required emotion response\n",
    "# result = pd.concat([temp_AUDIO_CUSTOMER, temp_ACC_MEAN, temp_EDA_MEAN, temp_EDA_PEAK, temp_EEG_MEAN_BANDPOWER, temp_TEMP_MEAN, temp_ECG_HRV, temp_ECG_HR, temp_LABEL], axis=1)\n",
    "\n",
    "# (7) 고객, 상담사, Physiological - 모두 포함\n",
    "result = pd.concat([\n",
    "    #temp_AUDIO_CUSTOMER, temp_AUDIO_WORKER, \n",
    "    temp_EDA_MEAN, temp_EDA_PEAK, temp_EEG_MEAN_BANDPOWER, temp_TEMP_MEAN, temp_ACC_MEAN, temp_ECG_HRV, temp_ECG_HR, temp_LABEL], axis=1)\n",
    "\n",
    "\n",
    "# result_nona = result.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDA_mean</th>\n",
       "      <th>EDA_std</th>\n",
       "      <th>EDA_min</th>\n",
       "      <th>EDA_max</th>\n",
       "      <th>phasic_mean</th>\n",
       "      <th>phasic_std</th>\n",
       "      <th>phasic_min</th>\n",
       "      <th>phasic_max</th>\n",
       "      <th>tonic_mean</th>\n",
       "      <th>tonic_std</th>\n",
       "      <th>...</th>\n",
       "      <th>bpm</th>\n",
       "      <th>sdnn</th>\n",
       "      <th>rmssd</th>\n",
       "      <th>pnn50</th>\n",
       "      <th>hr_mean</th>\n",
       "      <th>hr_std</th>\n",
       "      <th>call_label</th>\n",
       "      <th>call_three_label</th>\n",
       "      <th>suppress</th>\n",
       "      <th>pnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.134496</td>\n",
       "      <td>-1.111817</td>\n",
       "      <td>-3.153508</td>\n",
       "      <td>-2.949526</td>\n",
       "      <td>-0.968169</td>\n",
       "      <td>-1.047428</td>\n",
       "      <td>-0.638902</td>\n",
       "      <td>-1.107927</td>\n",
       "      <td>-3.343690</td>\n",
       "      <td>-0.358559</td>\n",
       "      <td>...</td>\n",
       "      <td>1.132466</td>\n",
       "      <td>1.313648</td>\n",
       "      <td>-0.998296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.874645</td>\n",
       "      <td>3.009427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.132410</td>\n",
       "      <td>-1.105120</td>\n",
       "      <td>-3.153508</td>\n",
       "      <td>-2.949526</td>\n",
       "      <td>-0.984024</td>\n",
       "      <td>-1.052600</td>\n",
       "      <td>-0.526180</td>\n",
       "      <td>-1.107927</td>\n",
       "      <td>-3.333681</td>\n",
       "      <td>-0.186736</td>\n",
       "      <td>...</td>\n",
       "      <td>1.335617</td>\n",
       "      <td>1.017973</td>\n",
       "      <td>-0.999339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.966540</td>\n",
       "      <td>3.170947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.134362</td>\n",
       "      <td>-1.111576</td>\n",
       "      <td>-3.153508</td>\n",
       "      <td>-2.949526</td>\n",
       "      <td>-1.032241</td>\n",
       "      <td>-1.117802</td>\n",
       "      <td>-0.568930</td>\n",
       "      <td>-1.136465</td>\n",
       "      <td>-3.311891</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>...</td>\n",
       "      <td>1.502637</td>\n",
       "      <td>0.507330</td>\n",
       "      <td>-1.148316</td>\n",
       "      <td>0</td>\n",
       "      <td>1.136715</td>\n",
       "      <td>3.009427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.127229</td>\n",
       "      <td>-1.108366</td>\n",
       "      <td>-3.153508</td>\n",
       "      <td>-2.949526</td>\n",
       "      <td>-1.071664</td>\n",
       "      <td>-1.187751</td>\n",
       "      <td>-0.594925</td>\n",
       "      <td>-1.207510</td>\n",
       "      <td>-3.284011</td>\n",
       "      <td>0.047605</td>\n",
       "      <td>...</td>\n",
       "      <td>1.699168</td>\n",
       "      <td>-0.112358</td>\n",
       "      <td>-1.140137</td>\n",
       "      <td>0</td>\n",
       "      <td>1.417503</td>\n",
       "      <td>2.041181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.107917</td>\n",
       "      <td>-1.095486</td>\n",
       "      <td>-3.147626</td>\n",
       "      <td>-2.934134</td>\n",
       "      <td>-1.095263</td>\n",
       "      <td>-1.237234</td>\n",
       "      <td>-0.594925</td>\n",
       "      <td>-1.264495</td>\n",
       "      <td>-3.254785</td>\n",
       "      <td>-0.037594</td>\n",
       "      <td>...</td>\n",
       "      <td>1.773269</td>\n",
       "      <td>-0.593977</td>\n",
       "      <td>-1.338665</td>\n",
       "      <td>0</td>\n",
       "      <td>1.548538</td>\n",
       "      <td>1.267529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>-1.225691</td>\n",
       "      <td>-0.064179</td>\n",
       "      <td>-1.355709</td>\n",
       "      <td>-1.123805</td>\n",
       "      <td>-0.160755</td>\n",
       "      <td>0.044568</td>\n",
       "      <td>-0.632897</td>\n",
       "      <td>-0.145487</td>\n",
       "      <td>-1.376630</td>\n",
       "      <td>-0.357067</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.928069</td>\n",
       "      <td>-0.066790</td>\n",
       "      <td>1.113697</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.596295</td>\n",
       "      <td>0.101678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>-1.185856</td>\n",
       "      <td>-0.221338</td>\n",
       "      <td>-1.355709</td>\n",
       "      <td>-1.123805</td>\n",
       "      <td>-0.115465</td>\n",
       "      <td>-0.034660</td>\n",
       "      <td>-0.632897</td>\n",
       "      <td>-0.145487</td>\n",
       "      <td>-1.350067</td>\n",
       "      <td>-0.038117</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.974528</td>\n",
       "      <td>-0.264534</td>\n",
       "      <td>1.051256</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.671172</td>\n",
       "      <td>-0.205648</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>-1.138687</td>\n",
       "      <td>-0.474454</td>\n",
       "      <td>-1.305712</td>\n",
       "      <td>-1.123805</td>\n",
       "      <td>-0.071912</td>\n",
       "      <td>-0.121642</td>\n",
       "      <td>-0.387239</td>\n",
       "      <td>-0.145487</td>\n",
       "      <td>-1.314656</td>\n",
       "      <td>0.254449</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.902033</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>1.138072</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.708610</td>\n",
       "      <td>-0.460745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>-1.094881</td>\n",
       "      <td>-0.646436</td>\n",
       "      <td>-1.102782</td>\n",
       "      <td>-1.123805</td>\n",
       "      <td>-0.068725</td>\n",
       "      <td>-0.132396</td>\n",
       "      <td>0.382150</td>\n",
       "      <td>-0.145487</td>\n",
       "      <td>-1.271607</td>\n",
       "      <td>0.491977</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.926701</td>\n",
       "      <td>0.030861</td>\n",
       "      <td>1.267376</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.764768</td>\n",
       "      <td>-0.848211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>-1.061977</td>\n",
       "      <td>-0.814157</td>\n",
       "      <td>-1.055726</td>\n",
       "      <td>-1.123805</td>\n",
       "      <td>-0.108895</td>\n",
       "      <td>-0.076384</td>\n",
       "      <td>0.070864</td>\n",
       "      <td>-0.145487</td>\n",
       "      <td>-1.222646</td>\n",
       "      <td>0.656841</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.917118</td>\n",
       "      <td>-0.007579</td>\n",
       "      <td>1.255820</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.802207</td>\n",
       "      <td>-1.114772</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EDA_mean   EDA_std   EDA_min   EDA_max  phasic_mean  phasic_std  \\\n",
       "0   -3.134496 -1.111817 -3.153508 -2.949526    -0.968169   -1.047428   \n",
       "1   -3.132410 -1.105120 -3.153508 -2.949526    -0.984024   -1.052600   \n",
       "2   -3.134362 -1.111576 -3.153508 -2.949526    -1.032241   -1.117802   \n",
       "3   -3.127229 -1.108366 -3.153508 -2.949526    -1.071664   -1.187751   \n",
       "4   -3.107917 -1.095486 -3.147626 -2.934134    -1.095263   -1.237234   \n",
       "..        ...       ...       ...       ...          ...         ...   \n",
       "747 -1.225691 -0.064179 -1.355709 -1.123805    -0.160755    0.044568   \n",
       "748 -1.185856 -0.221338 -1.355709 -1.123805    -0.115465   -0.034660   \n",
       "749 -1.138687 -0.474454 -1.305712 -1.123805    -0.071912   -0.121642   \n",
       "750 -1.094881 -0.646436 -1.102782 -1.123805    -0.068725   -0.132396   \n",
       "751 -1.061977 -0.814157 -1.055726 -1.123805    -0.108895   -0.076384   \n",
       "\n",
       "     phasic_min  phasic_max  tonic_mean  tonic_std  ...       bpm      sdnn  \\\n",
       "0     -0.638902   -1.107927   -3.343690  -0.358559  ...  1.132466  1.313648   \n",
       "1     -0.526180   -1.107927   -3.333681  -0.186736  ...  1.335617  1.017973   \n",
       "2     -0.568930   -1.136465   -3.311891  -0.005586  ...  1.502637  0.507330   \n",
       "3     -0.594925   -1.207510   -3.284011   0.047605  ...  1.699168 -0.112358   \n",
       "4     -0.594925   -1.264495   -3.254785  -0.037594  ...  1.773269 -0.593977   \n",
       "..          ...         ...         ...        ...  ...       ...       ...   \n",
       "747   -0.632897   -0.145487   -1.376630  -0.357067  ... -1.928069 -0.066790   \n",
       "748   -0.632897   -0.145487   -1.350067  -0.038117  ... -1.974528 -0.264534   \n",
       "749   -0.387239   -0.145487   -1.314656   0.254449  ... -1.902033  0.012139   \n",
       "750    0.382150   -0.145487   -1.271607   0.491977  ... -1.926701  0.030861   \n",
       "751    0.070864   -0.145487   -1.222646   0.656841  ... -1.917118 -0.007579   \n",
       "\n",
       "        rmssd  pnn50   hr_mean    hr_std  call_label  call_three_label  \\\n",
       "0   -0.998296      0  0.874645  3.009427         0.0               0.0   \n",
       "1   -0.999339      0  0.966540  3.170947         0.0               0.0   \n",
       "2   -1.148316      0  1.136715  3.009427         0.0               0.0   \n",
       "3   -1.140137      0  1.417503  2.041181         0.0               0.0   \n",
       "4   -1.338665      0  1.548538  1.267529         0.0               0.0   \n",
       "..        ...    ...       ...       ...         ...               ...   \n",
       "747  1.113697      0 -1.596295  0.101678         1.0               2.0   \n",
       "748  1.051256      0 -1.671172 -0.205648         1.0               2.0   \n",
       "749  1.138072      0 -1.708610 -0.460745         1.0               2.0   \n",
       "750  1.267376      0 -1.764768 -0.848211         1.0               2.0   \n",
       "751  1.255820      0 -1.802207 -1.114772         1.0               2.0   \n",
       "\n",
       "      suppress  pnum  \n",
       "0     0.000000     1  \n",
       "1     0.000000     1  \n",
       "2     0.000000     1  \n",
       "3     0.000000     1  \n",
       "4     0.583333     1  \n",
       "..         ...   ...  \n",
       "747  19.000000     1  \n",
       "748  19.000000     1  \n",
       "749  19.000000     1  \n",
       "750  19.000000     1  \n",
       "751  19.000000     1  \n",
       "\n",
       "[752 rows x 56 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_nona = result.dropna().reset_index(drop=True)\n",
    "result_nona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "열 제목:\n",
      "Index(['EDA_mean', 'EDA_std', 'EDA_min', 'EDA_max', 'phasic_mean',\n",
      "       'phasic_std', 'phasic_min', 'phasic_max', 'tonic_mean', 'tonic_std',\n",
      "       'tonic_min', 'tonic_max', 'peak', 'theta1', 'theta2', 'theta3',\n",
      "       'theta4', 'alpha_low1', 'alpha_low2', 'alpha_low3', 'alpha_low4',\n",
      "       'alpha_high1', 'alpha_high2', 'alpha_high3', 'alpha_high4', 'beta1',\n",
      "       'beta2', 'beta3', 'beta4', 'gamma1', 'gamma2', 'gamma3', 'gamma4',\n",
      "       'temp_mean', 'temp_std', 'temp_min', 'temp_max', 'temp_slope',\n",
      "       'accX_mean', 'accX_std', 'accY_mean', 'accY_std', 'accZ_mean',\n",
      "       'accZ_std', 'acc_magnitude', 'ibi', 'bpm', 'sdnn', 'rmssd', 'pnn50',\n",
      "       'hr_mean', 'hr_std', 'call_label', 'call_three_label', 'suppress',\n",
      "       'pnum'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"열 제목:\")\n",
    "print(result_nona.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (data):\n",
      "     EDA_mean   EDA_std   EDA_min   EDA_max  phasic_mean  phasic_std  \\\n",
      "0   -3.134496 -1.111817 -3.153508 -2.949526    -0.968169   -1.047428   \n",
      "1   -3.132410 -1.105120 -3.153508 -2.949526    -0.984024   -1.052600   \n",
      "2   -3.134362 -1.111576 -3.153508 -2.949526    -1.032241   -1.117802   \n",
      "3   -3.127229 -1.108366 -3.153508 -2.949526    -1.071664   -1.187751   \n",
      "4   -3.107917 -1.095486 -3.147626 -2.934134    -1.095263   -1.237234   \n",
      "..        ...       ...       ...       ...          ...         ...   \n",
      "747 -1.225691 -0.064179 -1.355709 -1.123805    -0.160755    0.044568   \n",
      "748 -1.185856 -0.221338 -1.355709 -1.123805    -0.115465   -0.034660   \n",
      "749 -1.138687 -0.474454 -1.305712 -1.123805    -0.071912   -0.121642   \n",
      "750 -1.094881 -0.646436 -1.102782 -1.123805    -0.068725   -0.132396   \n",
      "751 -1.061977 -0.814157 -1.055726 -1.123805    -0.108895   -0.076384   \n",
      "\n",
      "     phasic_min  phasic_max  tonic_mean  tonic_std  ...  accZ_mean  accZ_std  \\\n",
      "0     -0.638902   -1.107927   -3.343690  -0.358559  ...   1.545719 -0.734213   \n",
      "1     -0.526180   -1.107927   -3.333681  -0.186736  ...   1.521997 -0.724049   \n",
      "2     -0.568930   -1.136465   -3.311891  -0.005586  ...   1.498231 -0.727053   \n",
      "3     -0.594925   -1.207510   -3.284011   0.047605  ...   1.537092 -0.208217   \n",
      "4     -0.594925   -1.264495   -3.254785  -0.037594  ...   1.619951  0.205781   \n",
      "..          ...         ...         ...        ...  ...        ...       ...   \n",
      "747   -0.632897   -0.145487   -1.376630  -0.357067  ...   0.931707  0.376383   \n",
      "748   -0.632897   -0.145487   -1.350067  -0.038117  ...   1.072053  0.357891   \n",
      "749   -0.387239   -0.145487   -1.314656   0.254449  ...   1.213684  0.125485   \n",
      "750    0.382150   -0.145487   -1.271607   0.491977  ...   1.339258 -0.426854   \n",
      "751    0.070864   -0.145487   -1.222646   0.656841  ...   1.362060 -0.765623   \n",
      "\n",
      "     acc_magnitude       ibi       bpm      sdnn     rmssd  pnn50   hr_mean  \\\n",
      "0         0.589462 -1.139043  1.132466  1.313648 -0.998296      0  0.874645   \n",
      "1         0.508046 -1.316761  1.335617  1.017973 -0.999339      0  0.966540   \n",
      "2         0.415023 -1.459716  1.502637  0.507330 -1.148316      0  1.136715   \n",
      "3         0.593451 -1.624406  1.699168 -0.112358 -1.140137      0  1.417503   \n",
      "4         0.765410 -1.685536  1.773269 -0.593977 -1.338665      0  1.548538   \n",
      "..             ...       ...       ...       ...       ...    ...       ...   \n",
      "747       0.873301  2.175353 -1.928069 -0.066790  1.113697      0 -1.596295   \n",
      "748       0.816766  2.237101 -1.974528 -0.264534  1.051256      0 -1.671172   \n",
      "749       0.649648  2.140931 -1.902033  0.012139  1.138072      0 -1.708610   \n",
      "750      -0.968135  2.173541 -1.926701  0.030861  1.267376      0 -1.764768   \n",
      "751      -0.404612  2.160859 -1.917118 -0.007579  1.255820      0 -1.802207   \n",
      "\n",
      "       hr_std  \n",
      "0    3.009427  \n",
      "1    3.170947  \n",
      "2    3.009427  \n",
      "3    2.041181  \n",
      "4    1.267529  \n",
      "..        ...  \n",
      "747  0.101678  \n",
      "748 -0.205648  \n",
      "749 -0.460745  \n",
      "750 -0.848211  \n",
      "751 -1.114772  \n",
      "\n",
      "[752 rows x 52 columns]\n",
      "\n",
      "Y (label):\n",
      "      suppress\n",
      "0     0.000000\n",
      "1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.583333\n",
      "..         ...\n",
      "747  19.000000\n",
      "748  19.000000\n",
      "749  19.000000\n",
      "750  19.000000\n",
      "751  19.000000\n",
      "\n",
      "[752 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 필요한 열을 선택하여 x와 y 생성\n",
    "X = result_nona[['EDA_mean', 'EDA_std', 'EDA_min', 'EDA_max', 'phasic_mean',\n",
    "       'phasic_std', 'phasic_min', 'phasic_max', 'tonic_mean', 'tonic_std',\n",
    "       'tonic_min', 'tonic_max', 'peak', 'theta1', 'theta2', 'theta3',\n",
    "       'theta4', 'alpha_low1', 'alpha_low2', 'alpha_low3', 'alpha_low4',\n",
    "       'alpha_high1', 'alpha_high2', 'alpha_high3', 'alpha_high4', 'beta1',\n",
    "       'beta2', 'beta3', 'beta4', 'gamma1', 'gamma2', 'gamma3', 'gamma4',\n",
    "       'temp_mean', 'temp_std', 'temp_min', 'temp_max', 'temp_slope',\n",
    "       'accX_mean', 'accX_std', 'accY_mean', 'accY_std', 'accZ_mean',\n",
    "       'accZ_std', 'acc_magnitude', 'ibi', 'bpm', 'sdnn', 'rmssd', 'pnn50',\n",
    "       'hr_mean', 'hr_std']]\n",
    "Y = result_nona[['suppress']]\n",
    "\n",
    "# 결과 확인\n",
    "print(\"X (data):\")\n",
    "print(X)\n",
    "\n",
    "print(\"\\nY (label):\")\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "# Boolean kernels\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#평균 기반 threshold\n",
    "from MKLpy.preprocessing.binarization import AverageBinarizer\n",
    "\n",
    "Y_tensor = torch.tensor(Y.values)\n",
    "binarizer = AverageBinarizer().fit(Y_tensor)\n",
    "Y = binarizer.transform(Y_tensor)\n",
    "\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0087, 0.0544, 0.0025,  ..., 0.0000, 0.5978, 0.9668],\n",
      "        [0.0091, 0.0559, 0.0025,  ..., 0.0000, 0.6183, 1.0000],\n",
      "        [0.0088, 0.0544, 0.0025,  ..., 0.0000, 0.6563, 0.9668],\n",
      "        ...,\n",
      "        [0.3536, 0.2016, 0.3148,  ..., 0.0000, 0.0209, 0.2528],\n",
      "        [0.3612, 0.1619, 0.3491,  ..., 0.0000, 0.0084, 0.1731],\n",
      "        [0.3668, 0.1231, 0.3570,  ..., 0.0000, 0.0000, 0.1182]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from MKLpy.preprocessing import \\\n",
    "    normalization, rescale_01, rescale, centering\n",
    "from MKLpy.utils.validation import check_X\n",
    "\n",
    "X_numpy = X.values  # Convert DataFrame to a NumPy array\n",
    "X_tensor = torch.tensor(X_numpy, dtype=torch.float32) #numpy -> tensor \n",
    "#X_tensor = check_X(X_tensor)\n",
    "\n",
    "X = rescale_01(X_tensor)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[46.3728, 49.0174, 45.1239,  ...,  8.4239,  7.9250,  7.4481],\n",
      "        [49.0174, 52.2011, 48.4619,  ...,  8.4803,  7.9985,  7.5041],\n",
      "        [45.1239, 48.4619, 46.3228,  ...,  7.7296,  7.2702,  6.8384],\n",
      "        ...,\n",
      "        [ 8.4239,  8.4803,  7.7296,  ..., 25.4258, 24.5183, 23.6930],\n",
      "        [ 7.9250,  7.9985,  7.2702,  ..., 24.5183, 24.8599, 24.2267],\n",
      "        [ 7.4481,  7.5041,  6.8384,  ..., 23.6930, 24.2267, 24.1406]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from MKLpy.metrics.pairwise import homogeneous_polynomial_kernel as hpk\n",
    "K_train = hpk(X, degree=2)\n",
    "#K_test  = hpk(X, degree=2)\n",
    "print(K_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MKLpy.generators.HPK_generator object at 0x0000023F79E8DAB0>\n"
     ]
    }
   ],
   "source": [
    "from MKLpy.generators import HPK_generator\n",
    "KL = HPK_generator(X, degrees=range(1,11), cache=True)\n",
    "print(KL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#Y = Y.to_numpy()\n",
    "Y = Y.reshape(-1)\n",
    "\n",
    "print(Y)\n",
    "# train_test_split 함수를 사용하여 데이터 분할\n",
    "from MKLpy.model_selection import train_test_split\n",
    "\n",
    "# train 및 test 변수 정의\n",
    "KLtr, KLte, Ytr, Yte = train_test_split(KL, Y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[10.6842, 10.8544,  8.1578,  ..., 10.2040, 10.1779,  8.2512],\n",
      "        [10.8544, 12.2540,  8.9710,  ..., 10.5627, 10.3311,  8.4724],\n",
      "        [ 8.1578,  8.9710,  7.9478,  ...,  7.7274,  8.0698,  6.3110],\n",
      "        ...,\n",
      "        [10.2040, 10.5627,  7.7274,  ..., 12.0176, 10.1612,  8.5024],\n",
      "        [10.1779, 10.3311,  8.0698,  ..., 10.1612, 11.0149,  7.6585],\n",
      "        [ 8.2512,  8.4724,  6.3110,  ...,  8.5024,  7.6585,  7.6259]],\n",
      "       dtype=torch.float64), tensor([[114.1514, 117.8171,  66.5501,  ..., 104.1208, 103.5888,  68.0826],\n",
      "        [117.8171, 150.1593,  80.4789,  ..., 111.5697, 106.7312,  71.7817],\n",
      "        [ 66.5501,  80.4789,  63.1680,  ...,  59.7128,  65.1209,  39.8283],\n",
      "        ...,\n",
      "        [104.1208, 111.5697,  59.7128,  ..., 144.4231, 103.2494,  72.2903],\n",
      "        [103.5888, 106.7312,  65.1209,  ..., 103.2494, 121.3273,  58.6533],\n",
      "        [ 68.0826,  71.7817,  39.8283,  ...,  72.2903,  58.6533,  58.1541]],\n",
      "       dtype=torch.float64), tensor([[1219.6120, 1278.8284,  542.9045,  ..., 1062.4450, 1054.3115,\n",
      "          561.7646],\n",
      "        [1278.8284, 1840.0453,  721.9762,  ..., 1178.4727, 1102.6491,\n",
      "          608.1641],\n",
      "        [ 542.9045,  721.9762,  502.0488,  ...,  461.4249,  525.5095,\n",
      "          251.3547],\n",
      "        ...,\n",
      "        [1062.4450, 1178.4727,  461.4249,  ..., 1735.6216, 1049.1345,\n",
      "          614.6391],\n",
      "        [1054.3115, 1102.6491,  525.5095,  ..., 1049.1345, 1336.4046,\n",
      "          449.1987],\n",
      "        [ 561.7646,  608.1641,  251.3547,  ...,  614.6391,  449.1987,\n",
      "          443.4767]], dtype=torch.float64), tensor([[13030.5352, 13880.8601,  4428.9206,  ..., 10841.1485, 10730.6316,\n",
      "          4635.2425],\n",
      "        [13880.8601, 22547.8270,  6476.8495,  ..., 12447.8029, 11391.5579,\n",
      "          5152.6154],\n",
      "        [ 4428.9206,  6476.8495,  3990.1994,  ...,  3565.6169,  4240.7310,\n",
      "          1586.2902],\n",
      "        ...,\n",
      "        [10841.1485, 12447.8029,  3565.6169,  ..., 20858.0353, 10660.4337,\n",
      "          5225.8893],\n",
      "        [10730.6316, 11391.5579,  4240.7310,  ..., 10660.4337, 14720.3205,\n",
      "          3440.2077],\n",
      "        [ 4635.2425,  5152.6154,  1586.2902,  ...,  5225.8893,  3440.2077,\n",
      "          3381.9023]], dtype=torch.float64), tensor([[139220.3801, 150667.8080,  36130.3667,  ..., 110622.6649,\n",
      "         109214.8275,  38246.4013],\n",
      "        [150667.8080, 276299.9890,  58103.8296,  ..., 131481.8721,\n",
      "         117687.1105,  43655.0666],\n",
      "        [ 36130.3667,  58103.8296,  31713.4324,  ...,  27552.9655,\n",
      "          34221.6473,  10011.0196],\n",
      "        ...,\n",
      "        [110622.6649, 131481.8721,  27552.9655,  ..., 250663.8735,\n",
      "         108322.4792,  44432.4498],\n",
      "        [109214.8275, 117687.1105,  34221.6473,  ..., 108322.4792,\n",
      "         162142.3950,  26346.9789],\n",
      "        [ 38246.4013,  43655.0666,  10011.0196,  ...,  44432.4498,\n",
      "          26346.9789,  25789.9987]], dtype=torch.float64), tensor([[1487453.4325, 1635402.1480,  294745.2697,  ..., 1128789.4442,\n",
      "         1111572.8353,  315579.4340],\n",
      "        [1635402.1480, 3385766.7929,  521249.5693,  ..., 1388797.9124,\n",
      "         1215835.1093,  369863.5946],\n",
      "        [ 294745.2697,  521249.5693,  252053.0158,  ...,  212912.9210,\n",
      "          276160.2026,   63179.1782],\n",
      "        ...,\n",
      "        [1128789.4442, 1388797.9124,  212912.9210,  ..., 3012382.3599,\n",
      "         1100683.1280,  377781.1734],\n",
      "        [1111572.8353, 1215835.1093,  276160.2026,  ..., 1100683.1280,\n",
      "         1785977.1589,  201779.4756],\n",
      "        [ 315579.4340,  369863.5946,   63179.1782,  ...,  377781.1734,\n",
      "          201779.4756,  196671.5695]], dtype=torch.float64), tensor([[15892197.0483, 17751238.4482,  2404480.8246,  ...,\n",
      "         11518124.3467, 11313428.7411,  2603915.0297],\n",
      "        [17751238.4482, 41489023.6406,  4676130.9076,  ...,\n",
      "         14669395.9439, 12560891.3850,  3133635.7788],\n",
      "        [ 2404480.8246,  4676130.9076,  2003274.8921,  ...,\n",
      "          1645264.3515,  2228544.3158,   398721.4816],\n",
      "        ...,\n",
      "        [11518124.3467, 14669395.9439,  1645264.3515,  ...,\n",
      "         36201656.6506, 11184228.4033,  3212035.6965],\n",
      "        [11313428.7411, 12560891.3850,  2228544.3158,  ...,\n",
      "         11184228.4033, 19672303.5490,  1545336.8253],\n",
      "        [ 2603915.0297,  3133635.7788,   398721.4816,  ...,\n",
      "          3212035.6965,  1545336.8253,  1499794.8139]], dtype=torch.float64), tensor([[1.6979e+08, 1.9268e+08, 1.9615e+07,  ..., 1.1753e+08, 1.1515e+08,\n",
      "         2.1485e+07],\n",
      "        [1.9268e+08, 5.0840e+08, 4.1950e+07,  ..., 1.5495e+08, 1.2977e+08,\n",
      "         2.6549e+07],\n",
      "        [1.9615e+07, 4.1950e+07, 1.5922e+07,  ..., 1.2714e+07, 1.7984e+07,\n",
      "         2.5163e+06],\n",
      "        ...,\n",
      "        [1.1753e+08, 1.5495e+08, 1.2714e+07,  ..., 4.3506e+08, 1.1364e+08,\n",
      "         2.7310e+07],\n",
      "        [1.1515e+08, 1.2977e+08, 1.7984e+07,  ..., 1.1364e+08, 2.1669e+08,\n",
      "         1.1835e+07],\n",
      "        [2.1485e+07, 2.6549e+07, 2.5163e+06,  ..., 2.7310e+07, 1.1835e+07,\n",
      "         1.1437e+07]], dtype=torch.float64), tensor([[1.8141e+09, 2.0914e+09, 1.6002e+08,  ..., 1.1993e+09, 1.1719e+09,\n",
      "         1.7728e+08],\n",
      "        [2.0914e+09, 6.2300e+09, 3.7633e+08,  ..., 1.6367e+09, 1.3406e+09,\n",
      "         2.2494e+08],\n",
      "        [1.6002e+08, 3.7633e+08, 1.2654e+08,  ..., 9.8243e+07, 1.4512e+08,\n",
      "         1.5880e+07],\n",
      "        ...,\n",
      "        [1.1993e+09, 1.6367e+09, 9.8243e+07,  ..., 5.2284e+09, 1.1548e+09,\n",
      "         2.3220e+08],\n",
      "        [1.1719e+09, 1.3406e+09, 1.4512e+08,  ..., 1.1548e+09, 2.3868e+09,\n",
      "         9.0639e+07],\n",
      "        [1.7728e+08, 2.2494e+08, 1.5880e+07,  ..., 2.3220e+08, 9.0639e+07,\n",
      "         8.7219e+07]], dtype=torch.float64), tensor([[1.9382e+10, 2.2701e+10, 1.3054e+09,  ..., 1.2237e+10, 1.1928e+10,\n",
      "         1.4628e+09],\n",
      "        [2.2701e+10, 7.6342e+10, 3.3761e+09,  ..., 1.7287e+10, 1.3850e+10,\n",
      "         1.9058e+09],\n",
      "        [1.3054e+09, 3.3761e+09, 1.0057e+09,  ..., 7.5917e+08, 1.1711e+09,\n",
      "         1.0022e+08],\n",
      "        ...,\n",
      "        [1.2237e+10, 1.7287e+10, 7.5917e+08,  ..., 6.2832e+10, 1.1734e+10,\n",
      "         1.9742e+09],\n",
      "        [1.1928e+10, 1.3850e+10, 1.1711e+09,  ..., 1.1734e+10, 2.6290e+10,\n",
      "         6.9416e+08],\n",
      "        [1.4628e+09, 1.9058e+09, 1.0022e+08,  ..., 1.9742e+09, 6.9416e+08,\n",
      "         6.6512e+08]], dtype=torch.float64)] [tensor([[ 7.3196,  7.7425,  5.9045,  ...,  6.7585,  7.2290,  6.1316],\n",
      "        [ 5.7577,  5.9144,  5.0989,  ...,  5.2057,  5.8716,  4.7337],\n",
      "        [ 8.0182,  8.4413,  6.6123,  ...,  7.4145,  7.8918,  6.0798],\n",
      "        ...,\n",
      "        [ 6.4348,  6.6949,  5.4311,  ...,  5.4254,  6.6742,  5.2243],\n",
      "        [10.2151, 10.6838,  7.7440,  ..., 11.4548,  9.9642,  8.6288],\n",
      "        [ 5.3782,  5.6323,  4.7975,  ...,  4.8595,  5.7832,  4.1218]],\n",
      "       dtype=torch.float64), tensor([[ 53.5768,  59.9469,  34.8632,  ...,  45.6769,  52.2585,  37.5960],\n",
      "        [ 33.1513,  34.9804,  25.9983,  ...,  27.0988,  34.4758,  22.4084],\n",
      "        [ 64.2914,  71.2560,  43.7221,  ...,  54.9753,  62.2807,  36.9634],\n",
      "        ...,\n",
      "        [ 41.4065,  44.8221,  29.4970,  ...,  29.4346,  44.5453,  27.2934],\n",
      "        [104.3479, 114.1431,  59.9701,  ..., 131.2113,  99.2846,  74.4559],\n",
      "        [ 28.9253,  31.7233,  23.0159,  ...,  23.6149,  33.4451,  16.9895]],\n",
      "       dtype=torch.float64), tensor([[ 392.1616,  464.1412,  205.8501,  ...,  308.7056,  377.7772,\n",
      "          230.5220],\n",
      "        [ 190.8756,  206.8885,  132.5614,  ...,  141.0669,  202.4284,\n",
      "          106.0755],\n",
      "        [ 515.5008,  601.4950,  289.1022,  ...,  407.6157,  491.5071,\n",
      "          224.7283],\n",
      "        ...,\n",
      "        [ 266.4422,  300.0804,  160.2012,  ...,  159.6931,  297.3058,\n",
      "          142.5893],\n",
      "        [1065.9230, 1219.4787,  464.4107,  ..., 1502.9927,  989.2876,\n",
      "          642.4639],\n",
      "        [ 155.5664,  178.6765,  110.4185,  ...,  114.7571,  193.4188,\n",
      "           70.0277]], dtype=torch.float64), tensor([[ 2870.4731,  3593.6307,  1215.4433,  ...,  2086.3768,  2730.9534,\n",
      "          1413.4587],\n",
      "        [ 1099.0071,  1223.6254,   675.9107,  ...,   734.3452,  1188.5801,\n",
      "           502.1345],\n",
      "        [ 4133.3849,  5077.4159,  1911.6216,  ...,  3022.2789,  3878.8802,\n",
      "          1366.2929],\n",
      "        ...,\n",
      "        [ 1714.4993,  2009.0162,   870.0702,  ...,   866.3927,  1984.2874,\n",
      "           744.9308],\n",
      "        [10888.4934, 13028.6368,  3596.4135,  ..., 17216.4066,  9857.4239,\n",
      "          5543.6816],\n",
      "        [  836.6702,  1006.3677,   529.7318,  ...,   557.6639,  1118.5741,\n",
      "           288.6422]], dtype=torch.float64), tensor([[ 21010.7643,  27823.8233,   7176.5941,  ...,  14100.7085,\n",
      "          19742.0782,   8666.7031],\n",
      "        [  6327.7689,   7237.0341,   3446.3682,  ...,   3822.7448,\n",
      "           6978.8776,   2376.9775],\n",
      "        [ 33142.2741,  42860.1236,  12640.1550,  ...,  22408.7776,\n",
      "          30611.3830,   8306.7236],\n",
      "        ...,\n",
      "        [ 11032.4414,  13450.2174,   4725.4469,  ...,   4700.4940,\n",
      "          13243.5895,   3891.7496],\n",
      "        [111226.8767, 139195.0271,  27850.7582,  ..., 197209.6389,\n",
      "          98220.9863,  47835.2280],\n",
      "        [  4499.7965,   5668.2092,   2541.3826,  ...,   2709.9772,\n",
      "           6468.9079,   1189.7338]], dtype=torch.float64), tensor([[ 153790.7520,  215427.0168,   42374.2538,  ...,   95299.1708,\n",
      "          142715.5983,   53140.3855],\n",
      "        [  36433.4861,   42802.8555,   17572.5186,  ...,   19899.8757,\n",
      "           40977.2393,   11252.0095],\n",
      "        [ 265741.1232,  361796.2846,   83580.0986,  ...,  166150.5561,\n",
      "          241579.2017,   50502.8298],\n",
      "        ...,\n",
      "        [  70991.4349,   90048.2270,   25664.4204,  ...,   25501.8804,\n",
      "           88390.7568,   20331.7080],\n",
      "        [1136191.9044, 1487128.3870,  215677.2946,  ..., 2258987.1761,\n",
      "          978689.9959,  412759.8239],\n",
      "        [  24200.8960,   31925.3045,   12192.2555,  ...,   13169.1808,\n",
      "           37410.8144,    4903.8790]], dtype=torch.float64), tensor([[1.1257e+06, 1.6680e+06, 2.5020e+05,  ..., 6.4408e+05, 1.0317e+06,\n",
      "         3.2583e+05],\n",
      "        [2.0977e+05, 2.5315e+05, 8.9600e+04,  ..., 1.0359e+05, 2.4060e+05,\n",
      "         5.3264e+04],\n",
      "        [2.1308e+06, 3.0540e+06, 5.5265e+05,  ..., 1.2319e+06, 1.9065e+06,\n",
      "         3.0704e+05],\n",
      "        ...,\n",
      "        [4.5681e+05, 6.0287e+05, 1.3939e+05,  ..., 1.3836e+05, 5.8994e+05,\n",
      "         1.0622e+05],\n",
      "        [1.1606e+07, 1.5888e+07, 1.6702e+06,  ..., 2.5876e+07, 9.7518e+06,\n",
      "         3.5616e+06],\n",
      "        [1.3016e+05, 1.7981e+05, 5.8492e+04,  ..., 6.3996e+04, 2.1635e+05,\n",
      "         2.0213e+04]], dtype=torch.float64), tensor([[8.2396e+06, 1.2914e+07, 1.4773e+06,  ..., 4.3530e+06, 7.4581e+06,\n",
      "         1.9979e+06],\n",
      "        [1.2078e+06, 1.4973e+06, 4.5686e+05,  ..., 5.3926e+05, 1.4127e+06,\n",
      "         2.5214e+05],\n",
      "        [1.7085e+07, 2.5780e+07, 3.6543e+06,  ..., 9.1342e+06, 1.5046e+07,\n",
      "         1.8668e+06],\n",
      "        ...,\n",
      "        [2.9395e+06, 4.0361e+06, 7.5702e+05,  ..., 7.5064e+05, 3.9374e+06,\n",
      "         5.5492e+05],\n",
      "        [1.1856e+08, 1.6975e+08, 1.2934e+07,  ..., 2.9640e+08, 9.7169e+07,\n",
      "         3.0732e+07],\n",
      "        [7.0002e+05, 1.0128e+06, 2.8062e+05,  ..., 3.1099e+05, 1.2512e+06,\n",
      "         8.3314e+04]], dtype=torch.float64), tensor([[6.0311e+07, 9.9989e+07, 8.7227e+06,  ..., 2.9419e+07, 5.3915e+07,\n",
      "         1.2250e+07],\n",
      "        [6.9543e+06, 8.8554e+06, 2.3294e+06,  ..., 2.8072e+06, 8.2950e+06,\n",
      "         1.1936e+06],\n",
      "        [1.3699e+08, 2.1762e+08, 2.4163e+07,  ..., 6.7726e+07, 1.1874e+08,\n",
      "         1.1349e+07],\n",
      "        ...,\n",
      "        [1.8915e+07, 2.7022e+07, 4.1115e+06,  ..., 4.0725e+06, 2.6279e+07,\n",
      "         2.8991e+06],\n",
      "        [1.2111e+09, 1.8135e+09, 1.0016e+08,  ..., 3.3952e+09, 9.6821e+08,\n",
      "         2.6518e+08],\n",
      "        [3.7648e+06, 5.7043e+06, 1.3463e+06,  ..., 1.5113e+06, 7.2360e+06,\n",
      "         3.4341e+05]], dtype=torch.float64), tensor([[4.4145e+08, 7.7417e+08, 5.1504e+07,  ..., 1.9883e+08, 3.8975e+08,\n",
      "         7.5112e+07],\n",
      "        [4.0041e+07, 5.2375e+07, 1.1877e+07,  ..., 1.4613e+07, 4.8705e+07,\n",
      "         5.6500e+06],\n",
      "        [1.0984e+09, 1.8370e+09, 1.5977e+08,  ..., 5.0215e+08, 9.3706e+08,\n",
      "         6.9002e+07],\n",
      "        ...,\n",
      "        [1.2171e+08, 1.8091e+08, 2.2330e+07,  ..., 2.2095e+07, 1.7539e+08,\n",
      "         1.5146e+07],\n",
      "        [1.2371e+10, 1.9375e+10, 7.7566e+08,  ..., 3.8892e+10, 9.6474e+09,\n",
      "         2.2882e+09],\n",
      "        [2.0248e+07, 3.2129e+07, 6.4586e+06,  ..., 7.3440e+06, 4.1847e+07,\n",
      "         1.4155e+06]], dtype=torch.float64)] tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1]) tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(KLtr, KLte, Ytr, Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "base_learner = SVC(C=100)\n",
    "\n",
    "# from MKLpy.algorithms import EasyMKL\n",
    "# mkl = EasyMKL(lam=0.1, learner=base_learner)\n",
    "# mkl = mkl.fit(KLtr, Ytr)\n",
    "\n",
    "from MKLpy.algorithms import AverageMKL\n",
    "mkl = AverageMKL(learner=base_learner).fit(KLtr, Ytr) #base_learner에 svm, 로지스틱 회귀 (learner 명시적 선) Accuracy score: 0.6770, roc AUC score: 0.5101\n",
    "#mkl = AverageMKL(multiclass_strategy='ova').fit(KLtr, Ytr) #지정된 멀티클래스 전략을 사용(여러 클래스를 처리하기 위한) Accuracy score: 0.6770, roc AUC score: 0.5650\n",
    "#mkl = AverageMKL().fit(KLtr, Ytr)       #combine kernels and train the classifier (기본설정) Accuracy score: 0.6770, roc AUC score: 0.5650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds  = mkl.predict(KLte)            #predict the output class\n",
    "y_scores = mkl.decision_function(KLte)  #returns the projection on the distance vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1\n",
      " 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0 1 1 0 1\n",
      " 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1\n",
      " 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1\n",
      " 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1\n",
      " 0 0 0 1]\n",
      "[-2.44732872e+00 -2.82730062e+00  8.04967213e+00 -5.17225154e-01\n",
      " -3.09749764e+00 -3.83779133e+00  7.27940978e+00  1.60018479e+00\n",
      "  2.16510027e+00  5.40489392e+00  2.02644680e+01  1.73715092e+00\n",
      " -4.12872650e+00  1.49375920e+00  2.25354442e+00  2.64516840e+00\n",
      " -3.75483215e+00 -1.04302102e+00  1.43433311e+00 -9.63872222e+00\n",
      "  1.69351302e+00  1.91233961e+01 -5.85030780e-01  3.17218445e+00\n",
      "  1.66788759e+01 -9.09139540e-01  2.24896650e+00 -5.86307662e+00\n",
      "  8.83368992e+00  1.47433681e+00  9.99300331e-01  1.39936300e+01\n",
      "  8.05739804e-01 -1.13857928e+01  2.43714534e+00  2.97559046e+00\n",
      "  9.70445952e+00  1.84851880e+01 -5.60841281e+00  1.07395515e+00\n",
      " -6.29723680e+00  1.88044074e+01  1.51531680e+00 -1.08200809e+00\n",
      "  1.78502420e+01 -6.70774984e+00 -5.44264200e+00  5.64635944e+00\n",
      "  1.22876732e+00  3.76407580e+01  4.05562079e+00 -2.50309387e+00\n",
      "  2.48801504e+01  1.02635485e+00 -1.03787710e+00  2.18109792e+00\n",
      "  1.42366663e+00 -8.07006047e+00  1.45187898e+01  1.61330587e+00\n",
      "  3.39406250e+00  2.15998650e-01  1.01291588e+01  1.93071761e-01\n",
      " -2.35225035e+00  2.29169441e+01  5.86907486e+00 -5.46020946e+01\n",
      "  9.45927923e+00  1.12747108e+01  1.20650805e+00 -1.17106744e+01\n",
      " -4.31939169e+00  2.45530768e+01  9.94758979e+00 -4.47383009e+01\n",
      "  1.22965054e+01  1.55186981e-01  1.65475294e+00  5.24112345e+00\n",
      "  4.63061556e+00  5.27945476e+00  1.04012083e-01  7.55048657e+00\n",
      "  1.10192887e+00 -1.31287871e-02 -2.63940779e+00  1.98364126e+01\n",
      "  1.23710789e+01 -1.78514439e+00 -2.81856283e+00  1.47057306e+00\n",
      " -5.57779238e+01 -2.94782987e+00 -1.91059573e+01 -1.47492082e+01\n",
      "  2.09382436e+01  2.91336229e+00  3.17617729e+00 -7.07551519e+00\n",
      "  5.15567088e+00 -7.71229928e+00  3.34501652e+00  1.54766825e+00\n",
      "  9.18498181e+00 -8.89451460e+00 -2.63284101e+00  1.61712288e+01\n",
      "  4.26798596e-01 -8.07668395e+00  7.45730585e-01  4.07880401e+00\n",
      "  1.56555809e+01 -3.70488164e+00  2.91945066e-01 -5.55917290e-01\n",
      "  7.80997513e-01  2.05543835e+01  3.78642671e+01  1.78730366e+01\n",
      "  1.27708443e+00 -7.60636040e-01 -2.61545919e+00  3.08308563e+00\n",
      "  7.53870449e+00  9.07232316e-01  1.50773404e+00  3.89047636e+00\n",
      " -1.51307446e+01 -2.10708843e+00  4.22496345e+01 -3.53911565e+00\n",
      "  2.66017808e+00 -7.12599489e+01  1.24138409e+01  4.32364731e+00\n",
      "  9.43772345e+00  1.35440986e+01 -2.52410174e+00  7.59230837e+00\n",
      " -1.93786296e+00 -4.80710585e+00  7.43343351e+00  2.00241353e+01\n",
      " -1.09030756e+01  1.46129778e+01  1.74999420e+01  3.37512081e+00\n",
      "  2.06569282e+01  9.52399345e-01  8.30079058e+00 -2.43769014e+00\n",
      "  4.84950726e+00 -1.00681908e+00  6.57517811e+00  1.05949454e+00\n",
      " -6.63016304e+00  2.39318897e+00  2.96704270e+00  1.63466356e+00\n",
      "  4.30789683e+00 -1.04988042e+01  2.65453784e+01  1.03051040e+00\n",
      "  1.00017344e+00  1.51719004e+00  3.20026579e+00 -2.50615846e+00\n",
      "  1.85402757e+01  3.83066780e+00  2.08802123e+00  5.97819522e+00\n",
      "  2.71774137e+00 -2.26510599e+01  3.88265120e+00  2.87051449e+00\n",
      "  1.37020528e+01  1.49598489e+00  2.30329540e+00 -1.03127957e+00\n",
      "  9.28009733e+00 -1.61458714e+00  5.85889691e+00  4.66058361e+00\n",
      "  9.86329018e+00  1.60731398e+01 -7.45689651e+00 -4.53458482e+01\n",
      " -1.76722746e+01 -3.93280579e+00 -7.95984324e+00  9.92599998e-01\n",
      "  1.00827541e+01  3.48678431e+00  9.01719844e+00  9.84950859e-01\n",
      " -7.60924033e-01  2.13891999e+01 -1.24623328e+00 -1.19935700e+01\n",
      " -1.39068623e+00  1.60984807e+01 -2.26974146e-01  6.50145014e+00\n",
      "  2.15154666e+00  4.70366132e-01  9.81268401e+00 -9.58154685e+00\n",
      " -1.48965055e+00  1.92165192e+00  1.77378216e+00 -2.58814269e+00\n",
      "  1.41108312e+00  7.51021424e+00  2.17929313e+00  1.06635875e+01\n",
      " -1.37695096e+01  2.28783311e+01  6.37888296e+00  4.47357319e+00\n",
      " -1.74357581e+00  2.12063175e+01 -1.10220297e+01 -6.62668227e+00\n",
      " -3.06512751e+00  1.03965225e+00]\n"
     ]
    }
   ],
   "source": [
    "print(y_preds)\n",
    "print(y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9115, roc AUC score: 0.9329\n"
     ]
    }
   ],
   "source": [
    "#evaluation with scikit-learn metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "accuracy = accuracy_score(Yte, y_preds)\n",
    "roc_auc = roc_auc_score(Yte, y_scores)\n",
    "print ('Accuracy score: %.4f, roc AUC score: %.4f' % (accuracy, roc_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
